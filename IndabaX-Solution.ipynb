{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd0f5fe-da2a-4d74-96d5-df6e621ed684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics==8.1.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fcd37b-b8ef-4078-a7c9-9b5823967fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import re\n",
    "import matplotlib.patches as patches\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import wandb\n",
    "import glob\n",
    "import json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "exist=False\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b5a5e5-7d06-48d7-8410-acfb972edf62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "local_zip = 'test.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('test')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f120300b-d473-4577-8057-4785d4dbf2c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_zip = 'train.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('images')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72111984-d057-4bf2-b6f9-49501b604fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4313f5c9-cc3b-4742-a12b-1824fd29fefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unique_image_shapes_from_dataframe(CFG,df):\n",
    "    unique_shapes = []\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        image_path = CFG.images_path + row[CFG.image_id] + \".png\"\n",
    "        with Image.open(image_path) as img:\n",
    "            shape = img.size[::-1]  \n",
    "            if shape not in unique_shapes:\n",
    "                unique_shapes.append(shape)\n",
    "            df.iloc[index,7] = shape[0]\n",
    "    return unique_shapes\n",
    "\n",
    "\n",
    "def create_data_folder(destination_folder, df):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    unique_images = df[CFG.image_id].unique()\n",
    "    for img in unique_images:\n",
    "        img_path = os.path.join(CFG.images_path, img + '.png')\n",
    "        shutil.copy(img_path, destination_folder)\n",
    "        \n",
    "        \n",
    "def convert_bbox_to_string(row):\n",
    "    x_max = row['Xmax']\n",
    "    x_min = row['Xmin']\n",
    "    y_min = row['Ymin'] \n",
    "    y_max = row['Ymax'] \n",
    "    xc = int(np.round((x_min + x_max) / 2))\n",
    "    yc = int(np.round((y_min + y_max) / 2))\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    box = [xc/row['shape'], yc/row['shape'], w/row['shape'], h/row['shape']]\n",
    "    box = [f\"{i:.4g}\" for i in box]\n",
    "    return \" \".join(box)\n",
    "\n",
    "\n",
    "def create_label_folder(label_dir, dataframe):\n",
    "    if not os.path.exists(label_dir):\n",
    "        os.makedirs(label_dir)\n",
    "    unique_images = dataframe[CFG.image_id].unique()\n",
    "    for i,img in zip(tqdm(range(len(unique_images))), unique_images):\n",
    "        df = dataframe[dataframe[CFG.image_id] == img]\n",
    "        output_lines = []\n",
    "        for index, row in df.iterrows():\n",
    "            category_id = int(row[CFG.category_id]) \n",
    "            category_id=reversed_labels[category_id]\n",
    "            bbox_string = convert_bbox_to_string(row)\n",
    "            output_lines.append(f'{category_id} {bbox_string}')\n",
    "        with open(f\"{label_dir}/{img}.txt\", 'w') as f:\n",
    "            for line in output_lines:\n",
    "                f.write(line + '\\n')\n",
    "               \n",
    "            \n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error reading YAML:\", e)\n",
    "            return None\n",
    "\n",
    "        \n",
    "def print_yaml_data(data):\n",
    "    formatted_yaml = yaml.dump(data, default_style=False)\n",
    "    print(formatted_yaml)\n",
    "    \n",
    "\n",
    "def display_image(file_path, print_info=False, hide_axis=True):\n",
    "    img = mpimg.imread(file_path)\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    if print_info:\n",
    "        print(f\"File path: {file_path}\")\n",
    "        print(f\"Image shape: {img.shape}\")\n",
    "    if hide_axis:\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def convert_id (id):\n",
    "    return 'ID' + '_'+ ((6 - len(str(id)))*'0') + str(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70414c75-3c41-41c8-91f3-4a407de063cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels={0:11,1:12,2:13,3:14,4:15,5:16,6:17,7:18,8:21,9:22,10:23,11:24,12:25,13:26,14:27,15:28,16:31,17:32,18:33,19:34,20:35,21:36,22:37,23:38,24:41,25:42,26:43,27:44,28:45,29:46,30:47,31:48}\n",
    "reversed_labels = {value: key for key, value in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c00952-6240-4dd4-8d68-28dbc197b071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    train_path=\"Train.csv\"\n",
    "    test_path=\"Test.csv\"\n",
    "    train_dest_dir = \"/notebooks/train\"\n",
    "    val_dest_dir = \"/notebooks/val\"\n",
    "    train_destination_folder = \"/notebooks/train/images\"\n",
    "    val_destination_folder = \"/notebooks/val/images\"\n",
    "    train_destination_labels= \"/notebooks/train/labels\"\n",
    "    val_destination_labels= \"/notebooks/val/labels\"\n",
    "    images_path=\"images/train/\"\n",
    "    yaml=\"data.yaml\"\n",
    "    image_id = 'Image_ID' \n",
    "    category_id='ToothClass'\n",
    "    num_classes = 32\n",
    "    names=[i for i in range(32)]\n",
    "    model='yolov8m.pt'\n",
    "    task='detect'\n",
    "    EPOCHS = 60\n",
    "    BATCH_SIZE = 4\n",
    "    OPTIMIZER = \"auto\"\n",
    "    SEED = 42\n",
    "    DEVICE = [0]\n",
    "    VERBOSE = False\n",
    "    RESUME = False\n",
    "    PATIENCE = 5\n",
    "    img_size=512\n",
    "    lr0=0.018\n",
    "    momentum=0.947\n",
    "    weight_decay=0.0005\n",
    "    close_mosaic=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458a8d2b-5d3b-4bb0-a182-2f01feb1844f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>ToothClass</th>\n",
       "      <th>Xmin</th>\n",
       "      <th>Ymin</th>\n",
       "      <th>Xmax</th>\n",
       "      <th>Ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>284</td>\n",
       "      <td>315</td>\n",
       "      <td>325</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>372</td>\n",
       "      <td>119</td>\n",
       "      <td>448</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>325</td>\n",
       "      <td>236</td>\n",
       "      <td>379</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>200</td>\n",
       "      <td>362</td>\n",
       "      <td>237</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image_ID  ToothClass  Xmin  Ymin  Xmax  Ymax\n",
       "0         0          33   284   315   325   361\n",
       "1         0          37   372   119   448   193\n",
       "2         0          47    40   114   113   186\n",
       "3         0          35   325   236   379   287\n",
       "4         0          41   200   362   237   411"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(CFG.train_path)\n",
    "test = pd.read_csv(CFG.test_path)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b2e16c-5e83-450d-aa18-5968f5d839cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "folds = GroupKFold(n_splits=5)\n",
    "train['fold'] = -1\n",
    "for i,(train_index, test_index) in enumerate(folds.split(train,train[CFG.category_id], groups=train[CFG.image_id])): \n",
    "    train.loc[test_index,'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10457edd-9e8b-4107-b596-9b04b497af5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['Image_ID'] = [convert_id(id) for id in  list(train['Image_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b4daaf-07e0-49e6-a7ad-5770e0c0b27b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16013it [00:02, 6757.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train['shape']=0\n",
    "unique_shapes = get_unique_image_shapes_from_dataframe(CFG,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a52c47-e5b7-43e0-82a8-b48aea8d6a83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 1/5---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:01<00:00, 638.50it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 853.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 5\n",
      "- 6\n",
      "- 7\n",
      "- 8\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- 15\n",
      "- 16\n",
      "- 17\n",
      "- 18\n",
      "- 19\n",
      "- 20\n",
      "- 21\n",
      "- 22\n",
      "- 23\n",
      "- 24\n",
      "- 25\n",
      "- 26\n",
      "- 27\n",
      "- 28\n",
      "- 29\n",
      "- 30\n",
      "- 31\n",
      "nc: 32\n",
      "train: /notebooks/train\n",
      "val: /notebooks/val\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=60, time=None, patience=5, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=[0], workers=8, project=19-05-2024-11-01-57, name=Arm_Yolo_0, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.018, lrf=0.01, momentum=0.947, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0, flipud=0, fliplr=0, bgr=0, mosaic=0, mixup=0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=0, cfg=None, tracker=botsort.yaml, save_dir=19-05-2024-11-01-57/Arm_Yolo_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 11:02:02.344895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 11:02:02.344955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 11:02:02.346204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=32\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3794224  ultralytics.nn.modules.head.Detect           [32, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25874848 parameters, 25874832 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 19-05-2024-11-01-57/Arm_Yolo_0', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbouazizcss2001\u001b[0m (\u001b[33mbo3\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240519_110205-1enk5gss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/1enk5gss' target=\"_blank\">Arm_Yolo_0</a></strong> to <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/1enk5gss' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/1enk5gss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /notebooks/train/labels... 960 images, 0 backgrounds, 0 corrupt: 100%|██████████| 960/960 [00:01<00:00, 875.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /notebooks/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /notebooks/val/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 712.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /notebooks/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to 19-05-2024-11-01-57/Arm_Yolo_0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.018' and 'momentum=0.947' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000278, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_0\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60      2.09G     0.4594      1.701     0.8612         56        512: 100%|██████████| 240/240 [00:16<00:00, 14.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 20.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.907      0.793      0.866      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      2.33G     0.3422      0.457     0.8041         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.892      0.904      0.933      0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      2.33G     0.3112     0.3452     0.7947         58        512: 100%|██████████| 240/240 [00:13<00:00, 18.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.931      0.875       0.95      0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      2.33G     0.2901     0.2799     0.7889         55        512: 100%|██████████| 240/240 [00:13<00:00, 18.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.938      0.918      0.953      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      2.39G     0.2741     0.2375     0.7849         51        512: 100%|██████████| 240/240 [00:13<00:00, 18.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.958      0.923       0.97      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      2.35G     0.2475     0.2113      0.779         54        512: 100%|██████████| 240/240 [00:13<00:00, 18.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.935      0.947      0.973      0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      2.35G     0.2352     0.2009      0.776         50        512: 100%|██████████| 240/240 [00:13<00:00, 17.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.951      0.934      0.967      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      2.35G     0.2147     0.1852     0.7722         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.936      0.946      0.972      0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      2.33G     0.1922     0.1715     0.7682         51        512: 100%|██████████| 240/240 [00:13<00:00, 18.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.945      0.954      0.975       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      2.33G     0.1846     0.1655     0.7666         51        512: 100%|██████████| 240/240 [00:13<00:00, 18.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.953      0.944      0.973      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      2.33G     0.1665     0.1538     0.7635         55        512: 100%|██████████| 240/240 [00:13<00:00, 17.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.946      0.948      0.974       0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60      2.33G     0.1602     0.1492     0.7625         58        512: 100%|██████████| 240/240 [00:13<00:00, 17.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.953      0.934      0.971      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60      2.33G     0.1461     0.1394     0.7608         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.959      0.935      0.972      0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/60      2.33G     0.1388     0.1353     0.7595         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.951      0.936      0.972      0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/60      2.33G     0.1352     0.1316     0.7591         55        512: 100%|██████████| 240/240 [00:13<00:00, 17.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.961       0.94      0.974       0.92\n",
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 10, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 epochs completed in 0.067 hours.\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_0/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_0/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating 19-05-2024-11-01-57/Arm_Yolo_0/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.953      0.944      0.973      0.921\n",
      "Speed: 0.1ms preprocess, 3.5ms inference, 0.0ms loss, 7.3ms postprocess per image\n",
      "Results saved to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_0\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅████▇▇▇▇▇▇▆▆▆</td></tr><tr><td>lr/pg1</td><td>▁▅████▇▇▇▇▇▇▆▆▆</td></tr><tr><td>lr/pg2</td><td>▁▅████▇▇▇▇▇▇▆▆▆</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▅▆▇███████████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▅▆▇▇█▇████████</td></tr><tr><td>metrics/precision(B)</td><td>▃▁▅▆█▆▇▆▇▇▇▇█▇▇</td></tr><tr><td>metrics/recall(B)</td><td>▁▆▅▆▇█▇████▇▇▇█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▅▅▄▄▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▄▂▂▂▂▁▂▂▂▂▁▁▁▂</td></tr><tr><td>val/cls_loss</td><td>█▄▄▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▃▁▁▁▂▁▁▂▂▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00022</td></tr><tr><td>lr/pg1</td><td>0.00022</td></tr><tr><td>lr/pg2</td><td>0.00022</td></tr><tr><td>metrics/mAP50(B)</td><td>0.97326</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.9208</td></tr><tr><td>metrics/precision(B)</td><td>0.95326</td></tr><tr><td>metrics/recall(B)</td><td>0.9441</td></tr><tr><td>model/GFLOPs</td><td>79.166</td></tr><tr><td>model/parameters</td><td>25874848</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.627</td></tr><tr><td>train/box_loss</td><td>0.13517</td></tr><tr><td>train/cls_loss</td><td>0.13159</td></tr><tr><td>train/dfl_loss</td><td>0.75907</td></tr><tr><td>val/box_loss</td><td>0.33597</td></tr><tr><td>val/cls_loss</td><td>0.291</td></tr><tr><td>val/dfl_loss</td><td>0.8073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Arm_Yolo_0</strong> at: <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/1enk5gss' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/1enk5gss</a><br/> View job at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v0' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v0</a><br/>Synced 5 W&B file(s), 21 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_110205-1enk5gss/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '19-05-2024-11-01-57/Arm_Yolo_0/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 36, 5376) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.4s, saved as '19-05-2024-11-01-57/Arm_Yolo_0/weights/best.onnx' (98.8 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/notebooks/19-05-2024-11-01-57/Arm_Yolo_0/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=19-05-2024-11-01-57/Arm_Yolo_0/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=19-05-2024-11-01-57/Arm_Yolo_0/weights/best.onnx imgsz=512 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 69.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 2/5---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:01<00:00, 605.52it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 838.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 5\n",
      "- 6\n",
      "- 7\n",
      "- 8\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- 15\n",
      "- 16\n",
      "- 17\n",
      "- 18\n",
      "- 19\n",
      "- 20\n",
      "- 21\n",
      "- 22\n",
      "- 23\n",
      "- 24\n",
      "- 25\n",
      "- 26\n",
      "- 27\n",
      "- 28\n",
      "- 29\n",
      "- 30\n",
      "- 31\n",
      "nc: 32\n",
      "train: /notebooks/train\n",
      "val: /notebooks/val\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=60, time=None, patience=5, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=[0], workers=8, project=19-05-2024-11-01-57, name=Arm_Yolo_1, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.018, lrf=0.01, momentum=0.947, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0, flipud=0, fliplr=0, bgr=0, mosaic=0, mixup=0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=0, cfg=None, tracker=botsort.yaml, save_dir=19-05-2024-11-01-57/Arm_Yolo_1\n",
      "Overriding model.yaml nc=80 with nc=32\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3794224  ultralytics.nn.modules.head.Detect           [32, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25874848 parameters, 25874832 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 19-05-2024-11-01-57/Arm_Yolo_1', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240519_110652-j42lmjxh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j42lmjxh' target=\"_blank\">Arm_Yolo_1</a></strong> to <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j42lmjxh' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j42lmjxh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /notebooks/train/labels... 960 images, 0 backgrounds, 0 corrupt: 100%|██████████| 960/960 [00:01<00:00, 893.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /notebooks/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /notebooks/val/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 737.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /notebooks/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to 19-05-2024-11-01-57/Arm_Yolo_1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.018' and 'momentum=0.947' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000278, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_1\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60      3.73G     0.4558      1.661     0.8613         54        512: 100%|██████████| 240/240 [00:15<00:00, 15.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.913      0.797      0.846      0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      3.77G     0.3408     0.4498     0.8048         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.842      0.894      0.912      0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      3.89G     0.3139     0.3398     0.7956         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.882      0.929       0.94      0.881\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      3.89G     0.2959      0.275     0.7906         56        512: 100%|██████████| 240/240 [00:13<00:00, 18.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.907      0.939      0.949      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      3.87G     0.2722     0.2318     0.7852         48        512: 100%|██████████| 240/240 [00:13<00:00, 18.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.916      0.918      0.945       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      3.86G     0.2525     0.2105     0.7801         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.892       0.95       0.94      0.885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      3.86G     0.2338     0.1936     0.7766         49        512: 100%|██████████| 240/240 [00:13<00:00, 18.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203       0.93      0.932      0.948      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      3.85G     0.2161     0.1793     0.7725         50        512: 100%|██████████| 240/240 [00:13<00:00, 18.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.932      0.937      0.951      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      3.85G     0.1974     0.1683     0.7692         52        512: 100%|██████████| 240/240 [00:13<00:00, 18.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.903      0.927      0.946      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      3.84G     0.1795     0.1577      0.766         53        512: 100%|██████████| 240/240 [00:13<00:00, 18.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.928      0.939      0.948      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      3.85G     0.1651     0.1519     0.7638         56        512: 100%|██████████| 240/240 [00:13<00:00, 18.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.908      0.949      0.947      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60      3.85G     0.1578     0.1462     0.7624         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.933      0.933      0.952      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60      3.85G     0.1413     0.1381     0.7602         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.907      0.941      0.946      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/60      3.84G     0.1401      0.137     0.7598         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.904      0.936      0.946      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/60      3.85G     0.1341     0.1309     0.7588         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.906      0.943      0.953      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/60      3.85G     0.1303     0.1271     0.7582         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203       0.92      0.934      0.948      0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/60      3.85G     0.1168     0.1181      0.757         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.906      0.932      0.949      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/60      3.84G     0.1116      0.115     0.7563         47        512: 100%|██████████| 240/240 [00:13<00:00, 17.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.911      0.948      0.947      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/60      3.85G     0.1128      0.113     0.7563         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.918      0.935      0.949      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/60      3.85G     0.1049     0.1076     0.7556         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.917      0.937      0.948        0.9\n",
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 15, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.089 hours.\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_1/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_1/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating 19-05-2024-11-01-57/Arm_Yolo_1/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.906      0.943      0.953      0.903\n",
      "Speed: 0.1ms preprocess, 6.8ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆▆▅▅▅</td></tr><tr><td>lr/pg1</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆▆▅▅▅</td></tr><tr><td>lr/pg2</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆▆▅▅▅</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▅▇█▇▇██████████████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▅▇▇▇▇██▇████▇██████</td></tr><tr><td>metrics/precision(B)</td><td>▆▁▄▆▇▅██▆█▆█▆▆▆▇▆▆▇▆</td></tr><tr><td>metrics/recall(B)</td><td>▁▅▇█▇█▇▇▇▇█▇█▇█▇▇█▇█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▆▅▅▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▅▄▂▃▃▂▃▃▃▃▂▂▂▂▂▁▂▁▁</td></tr><tr><td>val/cls_loss</td><td>█▅▄▂▃▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▅▂▂▂▄▁▃▃▄▄▄▄▄▅▄▃▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0002</td></tr><tr><td>lr/pg1</td><td>0.0002</td></tr><tr><td>lr/pg2</td><td>0.0002</td></tr><tr><td>metrics/mAP50(B)</td><td>0.95261</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.90293</td></tr><tr><td>metrics/precision(B)</td><td>0.90627</td></tr><tr><td>metrics/recall(B)</td><td>0.94335</td></tr><tr><td>model/GFLOPs</td><td>79.166</td></tr><tr><td>model/parameters</td><td>25874848</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.017</td></tr><tr><td>train/box_loss</td><td>0.10493</td></tr><tr><td>train/cls_loss</td><td>0.10758</td></tr><tr><td>train/dfl_loss</td><td>0.75558</td></tr><tr><td>val/box_loss</td><td>0.33101</td></tr><tr><td>val/cls_loss</td><td>0.3251</td></tr><tr><td>val/dfl_loss</td><td>0.81103</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Arm_Yolo_1</strong> at: <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j42lmjxh' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j42lmjxh</a><br/> View job at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v1' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v1</a><br/>Synced 5 W&B file(s), 21 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_110652-j42lmjxh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '19-05-2024-11-01-57/Arm_Yolo_1/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 36, 5376) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.6s, saved as '19-05-2024-11-01-57/Arm_Yolo_1/weights/best.onnx' (98.8 MB)\n",
      "\n",
      "Export complete (3.4s)\n",
      "Results saved to \u001b[1m/notebooks/19-05-2024-11-01-57/Arm_Yolo_1/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=19-05-2024-11-01-57/Arm_Yolo_1/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=19-05-2024-11-01-57/Arm_Yolo_1/weights/best.onnx imgsz=512 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 68.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 3/5---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:01<00:00, 618.52it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 843.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 5\n",
      "- 6\n",
      "- 7\n",
      "- 8\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- 15\n",
      "- 16\n",
      "- 17\n",
      "- 18\n",
      "- 19\n",
      "- 20\n",
      "- 21\n",
      "- 22\n",
      "- 23\n",
      "- 24\n",
      "- 25\n",
      "- 26\n",
      "- 27\n",
      "- 28\n",
      "- 29\n",
      "- 30\n",
      "- 31\n",
      "nc: 32\n",
      "train: /notebooks/train\n",
      "val: /notebooks/val\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=60, time=None, patience=5, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=[0], workers=8, project=19-05-2024-11-01-57, name=Arm_Yolo_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.018, lrf=0.01, momentum=0.947, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0, flipud=0, fliplr=0, bgr=0, mosaic=0, mixup=0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=0, cfg=None, tracker=botsort.yaml, save_dir=19-05-2024-11-01-57/Arm_Yolo_2\n",
      "Overriding model.yaml nc=80 with nc=32\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3794224  ultralytics.nn.modules.head.Detect           [32, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25874848 parameters, 25874832 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 19-05-2024-11-01-57/Arm_Yolo_2', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240519_111254-j3pg82pr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j3pg82pr' target=\"_blank\">Arm_Yolo_2</a></strong> to <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j3pg82pr' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j3pg82pr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /notebooks/train/labels... 960 images, 0 backgrounds, 0 corrupt: 100%|██████████| 960/960 [00:01<00:00, 920.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /notebooks/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /notebooks/val/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 838.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /notebooks/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to 19-05-2024-11-01-57/Arm_Yolo_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.018' and 'momentum=0.947' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000278, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_2\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60       5.1G       0.46      1.665     0.8654         53        512: 100%|██████████| 240/240 [00:15<00:00, 15.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.916      0.797      0.861      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      5.27G     0.3437     0.4479     0.8065         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.919      0.862      0.919      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      5.38G     0.3187     0.3407     0.7981         50        512: 100%|██████████| 240/240 [00:13<00:00, 17.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203       0.92      0.876      0.913      0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      5.36G      0.299     0.2789     0.7921         54        512: 100%|██████████| 240/240 [00:13<00:00, 18.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.894      0.901      0.926      0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      5.37G     0.2763     0.2412      0.787         56        512: 100%|██████████| 240/240 [00:13<00:00, 18.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.932      0.897       0.94      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      5.37G     0.2545     0.2151     0.7819         54        512: 100%|██████████| 240/240 [00:13<00:00, 18.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.908      0.913      0.932      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      5.28G      0.241     0.1997     0.7785         55        512: 100%|██████████| 240/240 [00:13<00:00, 18.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.917      0.918      0.935      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      5.39G     0.2232     0.1859     0.7748         55        512: 100%|██████████| 240/240 [00:13<00:00, 18.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203       0.88      0.918      0.928      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      5.37G        0.2     0.1726     0.7709         50        512: 100%|██████████| 240/240 [00:13<00:00, 18.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.918      0.913       0.94      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      5.37G      0.182     0.1618     0.7679         51        512: 100%|██████████| 240/240 [00:13<00:00, 17.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.906      0.902      0.932      0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      5.37G      0.168     0.1545     0.7656         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.916      0.912      0.939      0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60      5.36G     0.1576     0.1478     0.7639         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.897      0.922      0.936      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60      5.36G     0.1494     0.1412     0.7625         51        512: 100%|██████████| 240/240 [00:13<00:00, 18.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.905      0.918      0.933      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/60      5.36G     0.1345     0.1319     0.7607         53        512: 100%|██████████| 240/240 [00:13<00:00, 18.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.926      0.902      0.933      0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/60      5.35G     0.1302     0.1289     0.7601         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.926      0.915      0.936      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/60      5.36G     0.1258     0.1252     0.7594         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.906      0.907      0.935      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 11, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "16 epochs completed in 0.071 hours.\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_2/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_2/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating 19-05-2024-11-01-57/Arm_Yolo_2/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3203      0.916      0.911       0.94      0.894\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆</td></tr><tr><td>lr/pg1</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆</td></tr><tr><td>lr/pg2</td><td>▁▅████▇▇▇▇▇▇▆▆▆▆</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▆▆▇█▇█▇█▇██▇▇██</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▆▅▆▇▇▇▇█▇█▇▇▇██</td></tr><tr><td>metrics/precision(B)</td><td>▆▆▆▃█▅▆▁▆▄▆▃▄▇▇▆</td></tr><tr><td>metrics/recall(B)</td><td>▁▅▅▇▇████▇▇██▇█▇</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/cls_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▄▅▂▃▂▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>val/cls_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▄▃▂▂▁▁▁▁▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00021</td></tr><tr><td>lr/pg1</td><td>0.00021</td></tr><tr><td>lr/pg2</td><td>0.00021</td></tr><tr><td>metrics/mAP50(B)</td><td>0.93975</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.89419</td></tr><tr><td>metrics/precision(B)</td><td>0.91555</td></tr><tr><td>metrics/recall(B)</td><td>0.911</td></tr><tr><td>model/GFLOPs</td><td>79.166</td></tr><tr><td>model/parameters</td><td>25874848</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>1.997</td></tr><tr><td>train/box_loss</td><td>0.12582</td></tr><tr><td>train/cls_loss</td><td>0.12519</td></tr><tr><td>train/dfl_loss</td><td>0.75937</td></tr><tr><td>val/box_loss</td><td>0.3231</td></tr><tr><td>val/cls_loss</td><td>0.30985</td></tr><tr><td>val/dfl_loss</td><td>0.79432</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Arm_Yolo_2</strong> at: <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j3pg82pr' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/j3pg82pr</a><br/> View job at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v2' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v2</a><br/>Synced 5 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_111254-j3pg82pr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '19-05-2024-11-01-57/Arm_Yolo_2/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 36, 5376) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.5s, saved as '19-05-2024-11-01-57/Arm_Yolo_2/weights/best.onnx' (98.8 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/notebooks/19-05-2024-11-01-57/Arm_Yolo_2/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=19-05-2024-11-01-57/Arm_Yolo_2/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=19-05-2024-11-01-57/Arm_Yolo_2/weights/best.onnx imgsz=512 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 70.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 4/5---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:01<00:00, 633.07it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 847.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 5\n",
      "- 6\n",
      "- 7\n",
      "- 8\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- 15\n",
      "- 16\n",
      "- 17\n",
      "- 18\n",
      "- 19\n",
      "- 20\n",
      "- 21\n",
      "- 22\n",
      "- 23\n",
      "- 24\n",
      "- 25\n",
      "- 26\n",
      "- 27\n",
      "- 28\n",
      "- 29\n",
      "- 30\n",
      "- 31\n",
      "nc: 32\n",
      "train: /notebooks/train\n",
      "val: /notebooks/val\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=60, time=None, patience=5, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=[0], workers=8, project=19-05-2024-11-01-57, name=Arm_Yolo_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.018, lrf=0.01, momentum=0.947, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0, flipud=0, fliplr=0, bgr=0, mosaic=0, mixup=0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=0, cfg=None, tracker=botsort.yaml, save_dir=19-05-2024-11-01-57/Arm_Yolo_3\n",
      "Overriding model.yaml nc=80 with nc=32\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3794224  ultralytics.nn.modules.head.Detect           [32, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25874848 parameters, 25874832 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 19-05-2024-11-01-57/Arm_Yolo_3', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240519_111748-fq3b7e7p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/fq3b7e7p' target=\"_blank\">Arm_Yolo_3</a></strong> to <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/fq3b7e7p' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/fq3b7e7p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /notebooks/train/labels... 960 images, 0 backgrounds, 0 corrupt: 100%|██████████| 960/960 [00:01<00:00, 918.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /notebooks/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /notebooks/val/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 733.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /notebooks/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to 19-05-2024-11-01-57/Arm_Yolo_3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.018' and 'momentum=0.947' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000278, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_3\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60      6.61G     0.4584      1.663     0.8619         53        512: 100%|██████████| 240/240 [00:15<00:00, 15.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.923      0.794       0.87      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      6.77G     0.3431     0.4595     0.8052         48        512: 100%|██████████| 240/240 [00:13<00:00, 17.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.916      0.847      0.913      0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      6.91G     0.3186     0.3472      0.797         49        512: 100%|██████████| 240/240 [00:13<00:00, 17.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.939      0.854      0.938      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      6.77G     0.2998     0.2831      0.791         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.893      0.932      0.941      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      6.88G     0.2785     0.2424     0.7855         45        512: 100%|██████████| 240/240 [00:13<00:00, 17.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202       0.93      0.947      0.962      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      6.87G     0.2531     0.2148     0.7805         55        512: 100%|██████████| 240/240 [00:13<00:00, 17.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.915       0.95      0.958      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      6.87G      0.236      0.201     0.7762         57        512: 100%|██████████| 240/240 [00:13<00:00, 17.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.895      0.955      0.955      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      6.87G     0.2181     0.1852     0.7724         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.936      0.958      0.966      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      6.87G     0.1998     0.1732     0.7689         50        512: 100%|██████████| 240/240 [00:13<00:00, 17.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.944      0.958      0.965      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      6.87G     0.1793     0.1634     0.7656         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.935      0.962      0.965      0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      6.87G     0.1774      0.163     0.7645         54        512: 100%|██████████| 240/240 [00:14<00:00, 16.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.933      0.952      0.965      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/60      6.87G     0.1616      0.151     0.7622         56        512: 100%|██████████| 240/240 [00:13<00:00, 17.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.939      0.941      0.966      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/60      6.87G     0.1517      0.145     0.7605         57        512: 100%|██████████| 240/240 [00:13<00:00, 17.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202       0.93      0.944      0.959      0.911\n",
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 8, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 epochs completed in 0.059 hours.\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_3/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_3/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating 19-05-2024-11-01-57/Arm_Yolo_3/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.936      0.958      0.967      0.914\n",
      "Speed: 0.2ms preprocess, 5.8ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅████▇▇▇▇▇▇▆</td></tr><tr><td>lr/pg1</td><td>▁▅████▇▇▇▇▇▇▆</td></tr><tr><td>lr/pg2</td><td>▁▅████▇▇▇▇▇▇▆</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▄▆▆█▇▇██████</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▄▆▆██▇██████</td></tr><tr><td>metrics/precision(B)</td><td>▅▄▇▁▆▄▁▇█▇▆▇▇</td></tr><tr><td>metrics/recall(B)</td><td>▁▃▄▇▇██████▇█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/cls_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▄▄▃▂▁▃▃▂▃▂▂▁</td></tr><tr><td>val/cls_loss</td><td>█▅▄▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▄▃▂▁▁▂▂▁▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00023</td></tr><tr><td>lr/pg1</td><td>0.00023</td></tr><tr><td>lr/pg2</td><td>0.00023</td></tr><tr><td>metrics/mAP50(B)</td><td>0.96715</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.91426</td></tr><tr><td>metrics/precision(B)</td><td>0.93601</td></tr><tr><td>metrics/recall(B)</td><td>0.95812</td></tr><tr><td>model/GFLOPs</td><td>79.166</td></tr><tr><td>model/parameters</td><td>25874848</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.009</td></tr><tr><td>train/box_loss</td><td>0.15168</td></tr><tr><td>train/cls_loss</td><td>0.14497</td></tr><tr><td>train/dfl_loss</td><td>0.76052</td></tr><tr><td>val/box_loss</td><td>0.32625</td></tr><tr><td>val/cls_loss</td><td>0.27641</td></tr><tr><td>val/dfl_loss</td><td>0.80374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Arm_Yolo_3</strong> at: <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/fq3b7e7p' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/fq3b7e7p</a><br/> View job at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v1' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v1</a><br/>Synced 5 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_111748-fq3b7e7p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '19-05-2024-11-01-57/Arm_Yolo_3/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 36, 5376) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.4s, saved as '19-05-2024-11-01-57/Arm_Yolo_3/weights/best.onnx' (98.8 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/notebooks/19-05-2024-11-01-57/Arm_Yolo_3/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=19-05-2024-11-01-57/Arm_Yolo_3/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=19-05-2024-11-01-57/Arm_Yolo_3/weights/best.onnx imgsz=512 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:08<00:00, 69.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------Training Fold 5/5---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960/960 [00:01<00:00, 612.21it/s]\n",
      "100%|██████████| 240/240 [00:00<00:00, 823.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "- 3\n",
      "- 4\n",
      "- 5\n",
      "- 6\n",
      "- 7\n",
      "- 8\n",
      "- 9\n",
      "- 10\n",
      "- 11\n",
      "- 12\n",
      "- 13\n",
      "- 14\n",
      "- 15\n",
      "- 16\n",
      "- 17\n",
      "- 18\n",
      "- 19\n",
      "- 20\n",
      "- 21\n",
      "- 22\n",
      "- 23\n",
      "- 24\n",
      "- 25\n",
      "- 26\n",
      "- 27\n",
      "- 28\n",
      "- 29\n",
      "- 30\n",
      "- 31\n",
      "nc: 32\n",
      "train: /notebooks/train\n",
      "val: /notebooks/val\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=data.yaml, epochs=60, time=None, patience=5, batch=4, imgsz=512, save=True, save_period=-1, cache=False, device=[0], workers=8, project=19-05-2024-11-01-57, name=Arm_Yolo_4, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.018, lrf=0.01, momentum=0.947, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0, perspective=0, flipud=0, fliplr=0, bgr=0, mosaic=0, mixup=0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=0, cfg=None, tracker=botsort.yaml, save_dir=19-05-2024-11-01-57/Arm_Yolo_4\n",
      "Overriding model.yaml nc=80 with nc=32\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3794224  ultralytics.nn.modules.head.Detect           [32, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25874848 parameters, 25874832 gradients, 79.2 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 19-05-2024-11-01-57/Arm_Yolo_4', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20240519_112204-vjyi5c88</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/vjyi5c88' target=\"_blank\">Arm_Yolo_4</a></strong> to <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/vjyi5c88' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/vjyi5c88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /notebooks/train/labels... 960 images, 0 backgrounds, 0 corrupt: 100%|██████████| 960/960 [00:01<00:00, 794.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /notebooks/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /notebooks/val/labels... 240 images, 0 backgrounds, 0 corrupt: 100%|██████████| 240/240 [00:00<00:00, 712.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /notebooks/val/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to 19-05-2024-11-01-57/Arm_Yolo_4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.018' and 'momentum=0.947' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000278, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_4\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/60       8.1G     0.4599      1.657     0.8615         46        512: 100%|██████████| 240/240 [00:15<00:00, 15.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.926      0.797      0.888      0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/60      8.41G     0.3458     0.4458     0.8033         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.861      0.915      0.942      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/60      8.37G     0.3148     0.3349     0.7942         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.943      0.881      0.942      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/60      8.37G     0.2952     0.2779     0.7888         57        512: 100%|██████████| 240/240 [00:13<00:00, 18.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.961      0.888      0.954      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/60      8.37G     0.2701     0.2341     0.7832         53        512: 100%|██████████| 240/240 [00:13<00:00, 17.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.906      0.939      0.949      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/60      8.36G     0.2491     0.2122     0.7784         54        512: 100%|██████████| 240/240 [00:13<00:00, 17.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.954      0.912      0.963      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/60      8.36G     0.2361     0.1987     0.7755         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.934       0.94      0.957      0.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/60      8.36G     0.2184     0.1802     0.7719         53        512: 100%|██████████| 240/240 [00:14<00:00, 17.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.966      0.915       0.96      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/60      8.36G     0.1967     0.1663     0.7683         57        512: 100%|██████████| 240/240 [00:13<00:00, 17.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 22.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.963      0.914      0.961      0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/60      8.36G     0.1782     0.1567     0.7653         54        512: 100%|██████████| 240/240 [00:14<00:00, 16.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.958      0.921      0.957      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/60      8.36G     0.1701     0.1522     0.7636         52        512: 100%|██████████| 240/240 [00:13<00:00, 17.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:01<00:00, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202       0.93      0.938      0.957      0.911\n",
      "Stopping training early as no improvement observed in last 5 epochs. Best results observed at epoch 6, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11 epochs completed in 0.050 hours.\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_4/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from 19-05-2024-11-01-57/Arm_Yolo_4/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating 19-05-2024-11-01-57/Arm_Yolo_4/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        240       3202      0.954      0.913      0.963      0.914\n",
      "Speed: 0.3ms preprocess, 14.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m19-05-2024-11-01-57/Arm_Yolo_4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁▅████▇▇▇▇▇</td></tr><tr><td>lr/pg1</td><td>▁▅████▇▇▇▇▇</td></tr><tr><td>lr/pg2</td><td>▁▅████▇▇▇▇▇</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▆▆▇▇█▇██▇█</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▆▆▇▇█▇████</td></tr><tr><td>metrics/precision(B)</td><td>▅▁▆█▄▇▆██▇▇</td></tr><tr><td>metrics/recall(B)</td><td>▁▇▅▅█▇█▇▇▇▇</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>█▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train/cls_loss</td><td>█▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/dfl_loss</td><td>█▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val/box_loss</td><td>█▅▃▂▁▂▂▁▁▂▂</td></tr><tr><td>val/cls_loss</td><td>█▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val/dfl_loss</td><td>█▃▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00024</td></tr><tr><td>lr/pg1</td><td>0.00024</td></tr><tr><td>lr/pg2</td><td>0.00024</td></tr><tr><td>metrics/mAP50(B)</td><td>0.96266</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.91383</td></tr><tr><td>metrics/precision(B)</td><td>0.95417</td></tr><tr><td>metrics/recall(B)</td><td>0.91251</td></tr><tr><td>model/GFLOPs</td><td>79.166</td></tr><tr><td>model/parameters</td><td>25874848</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.048</td></tr><tr><td>train/box_loss</td><td>0.1701</td></tr><tr><td>train/cls_loss</td><td>0.15217</td></tr><tr><td>train/dfl_loss</td><td>0.76361</td></tr><tr><td>val/box_loss</td><td>0.32955</td></tr><tr><td>val/cls_loss</td><td>0.29499</td></tr><tr><td>val/dfl_loss</td><td>0.79811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Arm_Yolo_4</strong> at: <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/runs/vjyi5c88' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/runs/vjyi5c88</a><br/> View job at <a href='https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v2' target=\"_blank\">https://wandb.ai/bo3/19-05-2024-11-01-57/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NjcxMDI1MA==/version_details/v2</a><br/>Synced 5 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240519_112204-vjyi5c88/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.33 🚀 Python-3.11.7 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 48677MiB)\n",
      "Model summary (fused): 218 layers, 25858288 parameters, 0 gradients, 78.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '19-05-2024-11-01-57/Arm_Yolo_4/weights/best.pt' with input shape (1, 3, 512, 512) BCHW and output shape(s) (1, 36, 5376) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.4s, saved as '19-05-2024-11-01-57/Arm_Yolo_4/weights/best.onnx' (98.8 MB)\n",
      "\n",
      "Export complete (1.9s)\n",
      "Results saved to \u001b[1m/notebooks/19-05-2024-11-01-57/Arm_Yolo_4/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=19-05-2024-11-01-57/Arm_Yolo_4/weights/best.onnx imgsz=512  \n",
      "Validate:        yolo val task=detect model=19-05-2024-11-01-57/Arm_Yolo_4/weights/best.onnx imgsz=512 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 65.47it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_images_test = test['Image_ID'].unique()\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "set_seed(42)\n",
    "sub=pd.DataFrame(columns=[\"Image_ID\"])\n",
    "score=[]\n",
    "subs = []\n",
    "for fold in range(5) :\n",
    "    sub_data = pd.DataFrame(columns=[\"Image_ID\", \"class\",'confidence','ymin','xmin','ymax','xmax'])\n",
    "    print(f'--------------------------------Training Fold {fold+1}/5---------------------------------')\n",
    "    NAME = f\"Arm_Yolo_{fold}\"\n",
    "    train_df = train[train.fold!=fold].reset_index()\n",
    "    val_df = train[train.fold==fold].reset_index()\n",
    "    if exist:\n",
    "        shutil.rmtree(CFG.train_dest_dir) \n",
    "        shutil.rmtree(CFG.val_dest_dir) \n",
    "    exist=True\n",
    "    create_data_folder(CFG.train_destination_folder, train_df)\n",
    "    create_data_folder(CFG.val_destination_folder, val_df)\n",
    "    create_label_folder(CFG.train_destination_labels, train_df)\n",
    "    create_label_folder(CFG.val_destination_labels, val_df)\n",
    "    dict_file = {\n",
    "        'train': CFG.train_dest_dir,\n",
    "        'val' : CFG.val_dest_dir,\n",
    "        'nc': CFG.num_classes,\n",
    "        'names': CFG.names\n",
    "        }\n",
    "    with open(CFG.yaml, 'w+') as file:\n",
    "        yaml.dump(dict_file, file)\n",
    "    yaml_data = read_yaml_file(CFG.yaml)\n",
    "    if yaml_data:\n",
    "        print_yaml_data(yaml_data)\n",
    "    model = YOLO(CFG.model)\n",
    "    model.train(\n",
    "        data = CFG.yaml,\n",
    "        project=timestamp,\n",
    "        save=True,\n",
    "        task = CFG.task,\n",
    "        imgsz = CFG.img_size,\n",
    "        epochs = CFG.EPOCHS,\n",
    "        pretrained=True,\n",
    "        batch = CFG.BATCH_SIZE,\n",
    "        optimizer = CFG.OPTIMIZER,\n",
    "        patience = CFG.PATIENCE,\n",
    "        name =  f\"Arm_Yolo_{fold}\",\n",
    "        seed = CFG.SEED,\n",
    "        val = True,\n",
    "        workers=8,\n",
    "        resume = CFG.RESUME,\n",
    "        device = CFG.DEVICE,\n",
    "        verbose =  CFG.VERBOSE,\n",
    "        lr0=CFG.lr0,\n",
    "        momentum=CFG.momentum,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        close_mosaic=CFG.close_mosaic,\n",
    "        hsv_h=0,\n",
    "        hsv_s=0,\n",
    "        hsv_v=0,\n",
    "        translate=0,\n",
    "        scale=0,\n",
    "        shear=0,\n",
    "        perspective=0,\n",
    "        flipud=0,\n",
    "        fliplr=0,\n",
    "        bgr=0,\n",
    "        mosaic=0,\n",
    "        mixup=0,\n",
    "        erasing=0,\n",
    "        crop_fraction=0\n",
    "    )\n",
    "    model.export(\n",
    "        format = 'onnx', \n",
    "        imgsz = CFG.img_size,\n",
    "        half = False,\n",
    "        int8 = False,\n",
    "        simplify = False,\n",
    "        nms = False,\n",
    "    )\n",
    "    for row in tqdm(unique_images_test, total=len(unique_images_test)):\n",
    "        pred = model.predict(f\"test/test/{row}.png\", imgsz=CFG.img_size)\n",
    "        d = {}\n",
    "        d['Image_ID'] = row\n",
    "        l= pred[0].boxes.cls.cpu().numpy().tolist()\n",
    "        d['confidence'] = pred[0].boxes.conf.cpu().numpy().tolist()\n",
    "        d['class']=[labels[i] for i in l]\n",
    "        d['ymin'] = [l[1] for l in pred[0].boxes.xyxy.cpu().numpy().tolist()]\n",
    "        d['xmin'] = [l[0] for l in pred[0].boxes.xyxy.cpu().numpy().tolist()]\n",
    "        d['ymax'] = [l[3] for l in pred[0].boxes.xyxy.cpu().numpy().tolist()]\n",
    "        d['xmax'] = [l[2] for l in pred[0].boxes.xyxy.cpu().numpy().tolist()]\n",
    "        pred_df = pd.DataFrame(d)\n",
    "        pred_df.reset_index(drop=True, inplace=True)  \n",
    "        sub_data = pd.concat([sub_data, pred_df], axis=0, ignore_index=True)\n",
    "    subs.append(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb403e60-9d92-4ce3-b77d-0ab6dd7db3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data = pd.DataFrame(columns=[\"Image_ID\", \"class\",'confidence','ymin','xmin','ymax','xmax'])\n",
    "sub0 = subs[0]\n",
    "sub1 = subs[1]\n",
    "sub2 = subs[2]\n",
    "sub3 = subs[3]\n",
    "sub4 = subs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "efecdb6f-703d-4a6a-b2c4-6d93985534df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data = pd.concat([sub_data, sub0])\n",
    "sub_data = pd.concat([sub_data, sub1])\n",
    "sub_data = pd.concat([sub_data, sub2])\n",
    "sub_data = pd.concat([sub_data, sub3])\n",
    "sub_data = pd.concat([sub_data, sub4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42151407-af1a-49b5-98f0-6fed39ff5f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data['Numeric_ID'] = sub_data['Image_ID'].str.extract(r'(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "35ba8226-3300-4754-84e9-bee316d14fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_df = sub_data.sort_values(by='Numeric_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9e9a8fa-2e85-4ffd-9c9b-a17c3a1ec995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_df = sorted_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "add92c91-af9b-4967-9058-8f78fffb5e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_df = sorted_df.groupby(['Image_ID', 'class']).agg({\n",
    "    'confidence': 'median',\n",
    "    'ymin': 'median',\n",
    "    'xmin': 'median',\n",
    "    'ymax': 'median',\n",
    "    'xmax': 'median',\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "deb2318c-f018-4938-af33-e04cbf1ef34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data = grouped_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fa89789a-f006-4c82-bed2-203d40f09f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data['class']=sub_data['class'].astype(int)\n",
    "sub_data['class']=sub_data['class'].astype(str)\n",
    "sub_data['class']='class_'+sub_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dda377cf-a682-4cf6-b351-59f47bab224a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data['xmax']=sub_data['xmax'].astype(int)\n",
    "sub_data['ymax']=sub_data['ymax'].astype(int)\n",
    "sub_data['xmin']=sub_data['xmin'].astype(int)\n",
    "sub_data['ymin']=sub_data['ymin'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74918692-e09d-4529-89e0-bf3318dd3834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>confidence</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_001200</td>\n",
       "      <td>class_31</td>\n",
       "      <td>0.928150</td>\n",
       "      <td>350</td>\n",
       "      <td>256</td>\n",
       "      <td>391</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_001200</td>\n",
       "      <td>class_32</td>\n",
       "      <td>0.976435</td>\n",
       "      <td>334</td>\n",
       "      <td>282</td>\n",
       "      <td>378</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_001200</td>\n",
       "      <td>class_33</td>\n",
       "      <td>0.976308</td>\n",
       "      <td>303</td>\n",
       "      <td>308</td>\n",
       "      <td>352</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_001200</td>\n",
       "      <td>class_34</td>\n",
       "      <td>0.969269</td>\n",
       "      <td>272</td>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_001200</td>\n",
       "      <td>class_35</td>\n",
       "      <td>0.975305</td>\n",
       "      <td>228</td>\n",
       "      <td>344</td>\n",
       "      <td>278</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>ID_001799</td>\n",
       "      <td>class_23</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>319</td>\n",
       "      <td>120</td>\n",
       "      <td>372</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>ID_001799</td>\n",
       "      <td>class_24</td>\n",
       "      <td>0.961857</td>\n",
       "      <td>280</td>\n",
       "      <td>97</td>\n",
       "      <td>328</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>ID_001799</td>\n",
       "      <td>class_25</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>239</td>\n",
       "      <td>75</td>\n",
       "      <td>287</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>ID_001799</td>\n",
       "      <td>class_26</td>\n",
       "      <td>0.980059</td>\n",
       "      <td>166</td>\n",
       "      <td>45</td>\n",
       "      <td>249</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>ID_001799</td>\n",
       "      <td>class_27</td>\n",
       "      <td>0.985815</td>\n",
       "      <td>120</td>\n",
       "      <td>32</td>\n",
       "      <td>182</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8137 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Image_ID     class  confidence  ymin  xmin  ymax  xmax\n",
       "0     ID_001200  class_31    0.928150   350   256   391   293\n",
       "1     ID_001200  class_32    0.976435   334   282   378   321\n",
       "2     ID_001200  class_33    0.976308   303   308   352   349\n",
       "3     ID_001200  class_34    0.969269   272   334   319   378\n",
       "4     ID_001200  class_35    0.975305   228   344   278   396\n",
       "...         ...       ...         ...   ...   ...   ...   ...\n",
       "8132  ID_001799  class_23    0.994975   319   120   372   167\n",
       "8133  ID_001799  class_24    0.961857   280    97   328   154\n",
       "8134  ID_001799  class_25    0.950104   239    75   287   134\n",
       "8135  ID_001799  class_26    0.980059   166    45   249   123\n",
       "8136  ID_001799  class_27    0.985815   120    32   182    89\n",
       "\n",
       "[8137 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1cfe9567-2054-4b70-8c59-fdb026039612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_data.to_csv('subfinale1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a70088-821d-46fe-897e-380527234dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
